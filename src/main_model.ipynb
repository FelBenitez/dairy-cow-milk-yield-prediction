{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce5db82",
   "metadata": {},
   "source": [
    "# Predicting Daily Milk Yield - Fall 2025 ML Course Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Felipe Benitez, feb478\n",
    "# Edwin Torres, EID\n",
    "# Gora Bepary, EID\n",
    "# Sankarsh Narayanan, EID\n",
    "\n",
    "'''\n",
    "Make cells to explain what dataset is\n",
    "Objective\n",
    "Tools used\n",
    "Summarizing final results, such like \"Best local CV RMSE... Best Kaggle RMSE... Kaggle LB Score..., etc.\" Things to orient reader.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430ff86",
   "metadata": {},
   "source": [
    "# Data Loading & Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Goal: show we know what we're working with before touching models.\n",
    "So show train/test. Other things we could show as example is train and test shape, train head, info, describe, # of rows/columns, target column, presence of categorical columns, missing values, just to name a few. Show whatever is important and useful. This will contribute to Data Exploration + Quality & Clarity.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac009a5e",
   "metadata": {},
   "source": [
    "# Data Cleaning Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e7e93",
   "metadata": {},
   "source": [
    "# Handling Missing Values 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Show how we handled missing values here and explain it. Like median, dropping impossible targets like milk yield < 0, etc. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd6f739",
   "metadata": {},
   "source": [
    "# Outliers 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Do what's needed here\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32770a7c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913258dc",
   "metadata": {},
   "source": [
    "# Target Distribution 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6959d",
   "metadata": {},
   "source": [
    "# Relationships with Key Features (or things we tried idk) 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd260ac",
   "metadata": {},
   "source": [
    "# Farm-Level Differences 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af9672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since we did farm clustering, show why and how, and also how it ended up being wrong in some way. Just talk about why we did this for example\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc4840f",
   "metadata": {},
   "source": [
    "# Feature Engineering 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d56b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Here we tell the story of our features\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da875272",
   "metadata": {},
   "source": [
    "### 5.1 Overview\n",
    "\n",
    "We did not just throw the raw CSV into CatBoost or XGBoost. We iteratively engineered features, tested them with cross validation, and only kept ideas that were neutral or helpful for RMSE. Most experiments were guided by dairy domain logic and short, focused code changes, followed by logging the new average CV RMSE. If a change made the model worse or clearly added noise, we removed it from the final pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fee4b58",
   "metadata": {},
   "source": [
    "### 5.2 Core CatBoost feature engineering\n",
    "\n",
    "For CatBoost we started from a clean baseline and then tried small, targeted feature blocks.\n",
    "\n",
    "Kept features and steps:\n",
    "\n",
    "- New biologically meaningful ratios:\n",
    "  - `Feed_per_kg_bw` (feed quantity divided by body weight).\n",
    "  - Temperature humidity index (THI) as a standard heat stress indicator.\n",
    "  - Grazing efficiency `Walk_per_graze` (distance walked over grazing hours).\n",
    "- Telling CatBoost exactly which columns are categorical so it can use its native categorical handling.\n",
    "- Dropping 74 rows with **negative** `Milk_Yield_L` labels because they are physically impossible and hurt training.\n",
    "- Lactation curve features such as `is_peak_lactation`, `is_early_lactation`, `is_late_lactation`, `dim_squared`, `dim_cubed`, `dim_log`, and `dim_parity`. These were mostly neutral but did not make things worse, so we kept them for biological interpretability.\n",
    "\n",
    "These changes moved CatBoost from about 4.114 RMSE down to about 4.108 on average, with dropping negative labels being the single biggest win.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e858824",
   "metadata": {},
   "source": [
    "### 5.3 CatBoost ideas that we tested but did not keep\n",
    "\n",
    "We also tried several larger “interaction blocks” that ended up hurting performance:\n",
    "\n",
    "- Additional efficiency ratios like `water_per_weight`, `age_parity_ratio`, `age_parity_product`, and combined activity metrics such as `total_activity` and `rest_activity_ratio`.\n",
    "- Extra interaction terms between temperature and humidity such as `temp_humidity` and heavy weight–feed products.\n",
    "- Bundling various vaccine columns and using sums or more complex combinations.\n",
    "\n",
    "These sets usually moved CatBoost’s average RMSE in the wrong direction, so we removed them from the final pipeline and kept only the simpler, more robust pieces. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0326d",
   "metadata": {},
   "source": [
    "### 5.4 Rumination and farm-level statistics\n",
    "\n",
    "We explored several ways to handle the strange `Rumination_Time_hrs` values and farm context:\n",
    "\n",
    "- Naively making all rumination values positive performed much worse.\n",
    "- A more careful approach that split positive and negative rumination into separate modes and created flags seemed conceptually better but did not beat the simpler baselines.\n",
    "- Setting negative rumination values to missing (NaN) and letting the model handle them was roughly neutral and is closer to how we would treat systemic sensor problems.\n",
    "- We added farm-level mean and standard deviation features per `Farm_ID` for important columns like `Weight_kg`, `Feed_Quantity_kg`, `Water_Intake_L`, `Age_Months`, `Days_in_Milk`, and `Ambient_Temperature_C`. These helped describe the overall environment of each farm without leaking label information.\n",
    "\n",
    "In the final model we kept a simpler rumination treatment and a lighter version of farm stats to avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc2d5c",
   "metadata": {},
   "source": [
    "### 5.5 Peer-relative features and clustering\n",
    "\n",
    "We tried two main ideas for farm context beyond simple stats:\n",
    "\n",
    "1. Peer-relative features  \n",
    "   For each farm we computed how a cow compares to its farm mates for key predictors like `Weight_kg`, `Age_Months`, `Days_in_Milk`, `Previous_Week_Avg_Yield`, `Water_Intake_L`, `Body_Condition_Score`, and `Feed_Quantity_kg`. For each column we created:\n",
    "   - A difference feature, like `Weight_kg_vs_farm_diff`.\n",
    "   - A ratio feature, like `Weight_kg_vs_farm_ratio`.\n",
    "\n",
    "   These were designed to capture “is this cow above or below the typical animal on this farm” rather than only absolute levels.\n",
    "\n",
    "2. Farm clustering  \n",
    "   We also experimented with clustering farms using KMeans on farm-level aggregates and using the cluster label as `Farm_Cluster`. However, doing this separately on train and test created mismatched cluster labels and effectively injected anti-signal in evaluation. Once we understood this, we removed `Farm_Cluster` and avoided that form of clustering in the final pipeline.\n",
    "\n",
    "Overall, peer-relative features were conceptually strong but did not clearly beat our simpler combination of farm stats and core predictors, so we relied more heavily on the latter in the final CatBoost version.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630eb21d",
   "metadata": {},
   "source": [
    "### 5.6 XGBoost feature engineering\n",
    "\n",
    "We also built an XGBoost pipeline to complement CatBoost and used it as a second family of models. We tried a wide range of engineered features:\n",
    "\n",
    "- Age and parity transforms: `Age_Years`, `Age_Years2`, `Parity2`, and `Age_x_Parity`.\n",
    "- Nonlinear day in milk transforms such as `DIM_log`.\n",
    "- Efficiency ratios: `Feed_per_kgBW`, `Water_per_kgBW`, and `PrevYield_per_Feed`.\n",
    "- Heat stress index THI and health summaries like `Vax_Sum`.\n",
    "- Farm deltas and cohort features that compare a cow’s performance to its farm or to breed plus lactation stage averages.\n",
    "- A large “biological feature block” including lactation curve flags, behavioral health indicators, parity categories, stress indicators, water and body condition flags, and age parity deviation.\n",
    "\n",
    "Most of these had very small effects on average XGBoost RMSE. The best improvements came from relatively simple parity categories, certain farm normalized predictors, and a `Vax_Sum` plus farm delta combination that gave a small but consistent gain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c78f4d1",
   "metadata": {},
   "source": [
    "### 5.7 Encodings and dimensionality reduction\n",
    "\n",
    "Instead of classic PCA style dimensionality reduction we focused on encodings that compress categorical structure in a supervised way.\n",
    "\n",
    "We tried:\n",
    "\n",
    "- Farm normalized predictors where we subtract or standardize by farm means and standard deviations for variables like `Previous_Week_Avg_Yield`, `Feed_Quantity_kg`, `Water_Intake_L`, and `Weight_kg`. This effectively reduces useless absolute scale variation and focuses on deviations within each farm.\n",
    "- KFold target encoding for several high signal categorical variables, with out of fold means on the training set and full train means on the test set, to avoid leakage.\n",
    "- Frequency encoding for some remaining categoricals like `Breed`.\n",
    "\n",
    "Target encoding in particular did not help XGBoost in this setup and sometimes hurt RMSE, so we removed it from the final feature set. Farm normalized predictors and simple parity categories were the most reliable pieces we kept. :contentReference[oaicite:5]{index=5}\n",
    "\n",
    "We considered PCA style dimensionality reduction on standardized numeric features, but since our strongest models are tree based and already handle moderate dimensionality well, PCA did not provide a clear benefit and would have reduced interpretability. We chose targeted feature selection, encoding, and dropping noisy columns instead of global projection methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e09f85",
   "metadata": {},
   "source": [
    "### 5.8 Final feature set used\n",
    "\n",
    "In the final models we kept a compact but expressive set of engineered features:\n",
    "\n",
    "- Cleaned labels with negative milk yields removed.\n",
    "- Date features like year, month, day of week, week of year, quarter, `date_ordinal`, and sometimes a weekend flag.\n",
    "- Key dairy science features: feed per body weight, THI, grazing efficiency, and lactation curve terms.\n",
    "- Light but useful farm context features based on per farm means and standard deviations.\n",
    "- Select efficiency and interaction terms that consistently did not hurt cross validation.\n",
    "- Parity categories and a small number of health and management summaries.\n",
    "\n",
    "We intentionally dropped many of the more complex interaction blocks and heavy encodings because they either did not help or made performance worse. This left us with a feature space that is easier to explain and tuned to what the cross validation actually supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f519a",
   "metadata": {},
   "source": [
    "## 6. Modeling Approach\n",
    "\n",
    "Our modeling work focused on gradient boosted tree methods. We compared CatBoost, LightGBM, and XGBoost using the same preprocessing pipeline and cross validation splits.\n",
    "\n",
    "Key steps:\n",
    "\n",
    "- Established baseline CatBoost and LightGBM models, which showed CatBoost was consistently stronger on this dataset.\n",
    "- Removed LightGBM from the final ensemble once we saw that blending it with CatBoost hurt leaderboard performance.\n",
    "- Tuned CatBoost with Optuna over depth, learning rate, regularization, subsample, random strength, and bagging temperature, reaching a best CV RMSE around 4.1064 with depth 6 and a five fold ensemble.\n",
    "- Built multiple CatBoost models using the best hyperparameters and different random seeds, then blended:\n",
    "  - CV only ensemble.\n",
    "  - Full data seed ensemble.\n",
    "  - Weighted blends between CV and full style predictions.\n",
    "- Trained and tuned an XGBoost model mainly as a diverse second opinion. It never beat CatBoost alone but helped us better understand which engineered features were robust across model classes.\n",
    "\n",
    "Overall, the best performing pipeline was an optimized CatBoost ensemble with carefully chosen features and tuned hyperparameters, rather than very heavy feature blocks or wide model diversity at all costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639ba8f",
   "metadata": {},
   "source": [
    "# Baseline Model (Modeling Approach) 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143db51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we show the baseline model we used w/ default ish paramaters. Show it, train it, run it, no optuna, show fold RMSEs, Average CV RMSEs, and explain what it's doing for us and anything else we can add to make this section full\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab589c7",
   "metadata": {},
   "source": [
    "# Modeling Experiments & Improvements 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ca258",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "Here show the process we took and not just the final script, subsections could be how we started with Catboost XGBoost and LightGBM (i have how we started in the doc), for each, show how we went on about it, and why we ended up choosing catboost as main model. We did a lot here so no reason to not uti`lize it all. Can make another subsection for hyperparamater tuning and how we used optuna, show the code or like how we integrated it and did it, show the outputs. Also we could show our cross validation strat. Also ensembles, like snapshot, seeds, blending, stacking. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762267c9",
   "metadata": {},
   "source": [
    "# Final Model & Leadership Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Short but important, here we show what we stuck with, why, the RMSE, final kaggle RMSE, show a table of the different `models we tried and their results, etc. Write a descr`iption of what we stuck with and why. As always, just make it good and useful for the reader\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8095a",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d81400",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What worked best (CatBoost, features, multi-seed ensemble, blending, alpha). What didnt help (Certain features, some stacking ideas which improved CV but not LB as you can seee in Felipe notebook. What we would do w/ more time)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
